# Food-Delivery-App-Data-Analysis
<img width="258" alt="food aap" src="https://user-images.githubusercontent.com/126523797/230689435-8158b8a7-5531-407d-a259-6546b7525077.png">

**Project Description:**

This project will help you understand how a real-world database is analyzed using SQL, how to get maximum available insights from the dataset, pre-process the data using python for better upcoming performance, and how a structured query language helps us retrieve useful information from the database.

This is the real world data analysis project conducted by HiCounselor as a 1 week challenge.

The real dataset, client requirements, the tools which will be used, everything related to the project had been given in a sandbox link in their website.
It Contains 2 modules:
In module 1, we have to do cleaning process which is done in 7 steps: 

Step 1 : Removing unwanted columns. 
For removing unwanted columns, first we have to load the Zomato dataset.<img width="1042" alt="dataset" src="https://user-images.githubusercontent.com/126523797/230700330-153470c3-e45d-4369-8bd8-19b181a05a31.png">

Then remove unwanted columns.
<img width="1032" alt="unwanted" src="https://user-images.githubusercontent.com/126523797/230700376-58a37b1a-a8f1-411c-8e2b-1a35d7240f9f.png">

Step 2 : Renaming the columns for easy analysis. 
<img width="1038" alt="rename" src="https://user-images.githubusercontent.com/126523797/230700414-1d6faaf3-000c-4c42-8a92-1ea43af3a3b1.png">

Step 3 : Dealing with Null values in every column. 
<img width="761" alt="null" src="https://user-images.githubusercontent.com/126523797/230700758-93140368-579d-470f-ba37-29c244928cf6.png">


Step 4 : Dropping the duplicate values.
<img width="1035" alt="duplicate" src="https://user-images.githubusercontent.com/126523797/230700527-f3c9e6ee-0130-48ba-a12d-95e40d7865c0.png">

Step 5 : Removing the irrelevant texts from each column.
<img width="1033" alt="irrevalent" src="https://user-images.githubusercontent.com/126523797/230700555-893caa31-822c-4ef8-9b36-b006ab46a54b.png">

Step 6 : Checking for unique values and handling the irrelevant ones. 
<img width="1032" alt="unique" src="https://user-images.githubusercontent.com/126523797/230700592-e47118c0-84e5-4ca2-834e-44e114e11e7d.png">

Step 7 : Removing the special characters from the dataset.
<img width="1031" alt="unknown" src="https://user-images.githubusercontent.com/126523797/230700620-dee4cc3d-6fa4-4f2f-817d-33ebb3c34095.png">

In module 2, we have to do our analysis using SQL queries.
